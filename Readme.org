* Table of Contents                                                   :TOC_5:
- [[#project-specifications][Project Specifications]]
  - [[#inherited-project][Inherited Project]]
    - [[#components][Components]]
    - [[#the-overview-component][The Overview Component]]
      - [[#build-process][Build Process]]
  - [[#related-projects][Related Projects]]
- [[#database-choices][Database Choices]]
- [[#development-journal][Development Journal]]
  - [[#local-database-testing][Local Database Testing]]
    - [[#refactor-to-build-on-a-local-machine][Refactor to build on a local machine.]]
    - [[#implement-crud-services-for-the-endpoint-33][Implement CRUD services for the endpoint]]
    - [[#setup-cassandra-locally][Setup Cassandra locally]]
    - [[#implement-connect-to-the-cassandra-from-the-server][IMPLEMENT Connect to the Cassandra from the server]]
    - [[#setup-postgres-locally][Setup Postgres locally]]
    - [[#implement-connect-to-the-postgres-from-the-server][IMPLEMENT Connect to the Postgres from the server]]
    - [[#implement-modify-seeding-script-to-store-10-million-records-0][IMPLEMENT Modify seeding script to store 10 million records]]
    - [[#test-ensure-api-responds-within-50ms][TEST Ensure API responds within 50ms]]
    - [[#research-dbms-benchmarking][RESEARCH DBMS benchmarking]]
    - [[#implement-stress-test-using-new-relic-to-monitor][IMPLEMENT Stress test using New Relic to monitor]]
    - [[#research-choose-dbms-to-move-forward-with][RESEARCH Choose DBMS to move forward with]]
  - [[#deployment][Deployment]]
    - [[#deploy-service][Deploy service]]
    - [[#deploy-proxy][Deploy proxy]]
    - [[#seed-deployed-database][Seed deployed database]]
    - [[#stress-test-service][Stress test service]]
    - [[#stress-test-proxy][Stress test proxy]]
  - [[#scale-the-service][Scale the service]]

* Project Specifications

The goal of this project is to explore system design by inheriting a front end focused project from another team and scaling it. The inherited project used Mongo to serve 100 records and needed to be scaled to handle 10 million records with at least 1000 requests per second (RPS) with the goal of hitting 10,000 RPS. The inherited project had four separate services and a proxy service.

** Inherited Project

The project I inherited was a clone of a game landing page on [[https://store.steampowered.com/][Steam]].

#+html: <p align="center"><img src="steam_screenshot.png" /></p>

*** Components

There are four components:
  1. An overview of the game on the top right (my service)
  2. A photo carousel on the top middle of the page
  3. Information about the game below the carousel
  4. Reviews for the game below the game information

*** The Overview Component

#+html: <p align="center"><img src="overview_screenshot.png" /></p>

It utilizes the reviews component to display an overall user feeling for the game ranging from Overwhelmingly Positive to Overwhelmingly Negative as well as general information such as the devloper and user tags.

Tech stack for this component:
 - Server: node
 - Package management: npm
 - Client: react, webpack, babel
 - DB: Cassandra / Postgres
 - Testing: jest
 - Deployment: Docker, docker-compose

The component had a seeding script for adding 100 records to a Mongo database which I modified to seed millions to either Cassandra or Postgres databases.

It defines a single endpoint ~/api/overview/:gameId~ which origininally only supported GET requests. In order to fully explore the databases I updated the endpoint to support full CRUD operations using GET, POST, PUT, DELETE http methods.

**** Build Process

Building and deployment is done using docker-compose.

The docker-compose.yml file defines the build process for the component and database containers and defines the following environment variables:

| ENV VAR      | DESCRIPTION                         | VALUES                  |
|--------------+-------------------------------------+-------------------------|
| NODE_ENV     | Specifies which database URI to use | production, development |
| PROD_DB_HOST | Production database URI             | defaults to localhost   |
| PROD_API_URL | Production server URI               | defaults to localhost   |

Run ~docker-compose up~ and navigate to localhost in your browser. The service maps port 80 to the component container's port 3000. 

Building locally can be done by cloning the repository and running the following commands:
 1. ~npm install~
 2. ~npm run db:setup~ to seed the database. Requires ~mongod~ running.
 3. ~npm run start~ and navigate to localhost:300
 4. If making changes run ~npm run build~ to rebuild the bundle.

** Related Projects

Proxy Service: https://github.com/rpt15-drKarp/stephen_proxy

Teammates Servies:
 - https://github.com/rpt15-drKarp/Richard_Reviews
 - https://github.com/rpt15-drKarp/stephen_photoCarousel
 - https://github.com/rpt15-drKarp/Therese_aboutGame

* Database Choices

Before trying to scale the backend it was important to choose a database. My service used Mongo, which I have used quite a bit, so I decided to explore two others before making a final choice.

After checking job listings in my area, MySQL and PostgreSQL came up the most, so I wanted to use at least one. PostgreSQL supports arrays and MySQL does not --at least not directly-- which simplifies the schema I would need to design for the overview component.

I have heard lots of Cassandra hate/grief from my peers but also know senior software engineers who love it. I chose it simply because I want to see for myself.

Final Choices:
 1. PostgreSQL
 2.  Cassandra

* Development Journal

This sections describes my process and results for this project.

** Local Database Testing

*** DONE Refactor to build on a local machine.

Changed PROD_DB_HOST to localhost and refactored hard coded referenses to AWS services out of the client.

Updated tests to pass for the schema in use. The response from the /api/overview/:gameID endpoint is an array with a single object which I did not expect. I did not change this to prevent breaking compatibility with the other components who consume this API.

Client test failed to run because of a parsing error with Babel.

*** DONE Implement CRUD services for the endpoint [3/3]
   - [X] Post -> Set location header to the GET endpoint for the new record
   - [X] Delete
   - [X] Put

Use with endpoint:
 - Post -> /api/overview
 - Delete -> /api/overview/:gameId
 - Put -> /api/overview/:gameId

Used promise based api from Mongoose for brevity for the additional database methods despite the inhertied code using callbacks. The inherited code uses a callback to send messages to the client from the database module but doesn't set the appropriate headers and doesn't set status codes for errors. Since getting the callbacks to work isn't required for my work I will ignore them.


*** DONE Setup Cassandra locally

Install process for Fedora via ~dnf~
 1. Run ~dnf install cassandra cassandra-server~
 2. Run ~systemctl start cassandra~
 3. Run ~systemctl enable cassandra~

Manually connect by running ~cqlsh~. 

I initially did not run ~systemctl start cassandra~ and could not connect via cqlsh. ~systemctl enable~ will automatically start the process on a reboot but not for the current session. The shell gave a very helpful message about not finding any servers to connect to. +1 for the helpful error.

*** IMPLEMENT Connect to the Cassandra from the server

*** DONE Setup Postgres locally

Install process for Fedora via ~dnf~:
 1. Run ~dnf install postgresql-server postgresql-contrib~
 2. Run ~postgresql-setup --initdb --unit postgresql~
 3. Run ~systemctl enable postgresql~
 4. Run ~systemctl start postgresql~

Manually connect to Postgres by running ~psql~.

I initially did not have step 2 and I tried to start the postgresql service but it would not run. Checking journalctl showed that it failed to start the database server. Some quick Googling revealed that I needed to setup the database by creating a data directory, setting the ownership to the postgres user, and initializing the database as the postgres user. Turns out there is also a Fedora package called ~postgresql-setup~ which can be used to do the same thing which is installed along with Postgres. I opted for the package.

*** IMPLEMENT Connect to the Postgres from the server

*** IMPLEMENT Modify seeding script to store 10 million records [0%]
    - [ ] Modular function for generating 10 million records
    - [ ] Cassandra save script
    - [ ] Postgres save script

*** TEST Ensure API responds within 50ms

*** RESEARCH DBMS benchmarking

*** IMPLEMENT Stress test using New Relic to monitor

| DBMS      | ROUTE |  RPS | LATENCY | ERROR RATE |
|-----------+-------+------+---------+------------|
| Cassandra | GET   |    1 |         |            |
| Cassandra | GET   |   10 |         |            |
| Cassandra | GET   |  100 |         |            |
| Cassandra | GET   | 1000 |         |            |
| Cassandra | POST  |    1 |         |            |
| Cassandra | POST  |   10 |         |            |
| Cassandra | POST  |  100 |         |            |
| Cassandra | POST  | 1000 |         |            |
| Postgres  | GET   |    1 |         |            |
| Postgres  | GET   |   10 |         |            |
| Postgres  | GET   |  100 |         |            |
| Postgres  | GET   | 1000 |         |            |
| Postgres  | POST  |    1 |         |            |
| Postgres  | POST  |   10 |         |            |
| Postgres  | POST  |  100 |         |            |
| Postgres  | POST  | 1000 |         |            |

*** RESEARCH Choose DBMS to move forward with

** Deployment

*** Deploy service

*** Deploy proxy

*** Seed deployed database

*** Stress test service

*** Stress test proxy

** Scale the service
